import json
import requests
import traceback
import datetime
import boto3
import os
import re
import info
import yfinance as yf

from pytz import timezone
from bs4 import BeautifulSoup
from botocore.config import Config

from langchain_core.prompts import ChatPromptTemplate
from langchain.docstore.document import Document
from langchain_aws import ChatBedrock
from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_aws import AmazonKnowledgeBasesRetriever
from urllib import parse
from pydantic.v1 import BaseModel, Field

bedrock_region = os.environ.get('bedrock_region')
projectName = os.environ.get('projectName')
path = os.environ.get('sharing_url')

model_name = "Nova Pro"
models = info.get_model_info(model_name)

secretsmanager = boto3.client(
    service_name='secretsmanager',
    region_name=bedrock_region
)
try:
    get_weather_api_secret = secretsmanager.get_secret_value(
        SecretId=f"openweathermap-{projectName}"
    )
    #print('get_weather_api_secret: ', get_weather_api_secret)
    secret = json.loads(get_weather_api_secret['SecretString'])
    #print('secret: ', secret)
    weather_api_key = secret['weather_api_key']

except Exception as e:
    raise e

# api key to use Tavily Search
tavily_key = ""
try:
    get_tavily_api_secret = secretsmanager.get_secret_value(
        SecretId=f"tavilyapikey-{projectName}"
    )
    #print('get_tavily_api_secret: ', get_tavily_api_secret)
    secret = json.loads(get_tavily_api_secret['SecretString'])
    #print('secret: ', secret)
    tavily_key = secret['tavily_api_key']
    #print('tavily_api_key: ', tavily_api_key)

    tavily_api_wrapper = TavilySearchAPIWrapper(tavily_api_key=tavily_key)
    #     os.environ["TAVILY_API_KEY"] = tavily_key

except Exception as e: 
    print('Tavily credential is required: ', e)
    raise e

def isKorean(text):
    # check korean
    pattern_hangul = re.compile('[\u3131-\u3163\uac00-\ud7a3]+')
    word_kor = pattern_hangul.search(str(text))
    # print('word_kor: ', word_kor)

    if word_kor and word_kor != 'None':
        print('Korean: ', word_kor)
        return True
    else:
        print('Not Korean: ', word_kor)
        return False
    
# Tools    
def get_book_list(keyword: str) -> str:
    """
    Search book list by keyword and then return book list
    keyword: search keyword
    return: book list
    """
    
    keyword = keyword.replace('\'','')

    answer = ""
    url = f"https://search.kyobobook.co.kr/search?keyword={keyword}&gbCode=TOT&target=total"
    response = requests.get(url)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, "html.parser")
        prod_info = soup.find_all("a", attrs={"class": "prod_info"})
        
        if len(prod_info):
            answer = "추천 도서는 아래와 같습니다.\n"
            
        for prod in prod_info[:5]:
            title = prod.text.strip().replace("\n", "")       
            link = prod.get("href")
            answer = answer + f"{title}, URL: {link}\n\n"
    
    return answer

selected_chat = 0
multi_region = 'Disable'
def get_chat():
    global selected_chat, model_type

    profile = models[selected_chat]
    print('profile: ', profile)
    number_of_models = len(models)
        
    bedrock_region =  profile['bedrock_region']
    modelId = profile['model_id']
    model_type = profile['model_type']
    if model_type == 'claude':
        maxOutputTokens = 4096 # 4k
    else:
        maxOutputTokens = 5120 # 5k
    print(f'LLM: {selected_chat}, bedrock_region: {bedrock_region}, modelId: {modelId}, model_type: {model_type}')

    if profile['model_type'] == 'nova':
        STOP_SEQUENCE = '"\n\n<thinking>", "\n<thinking>", " <thinking>"'
    elif profile['model_type'] == 'claude':
        STOP_SEQUENCE = "\n\nHuman:" 
                          
    # bedrock   
    boto3_bedrock = boto3.client(
        service_name='bedrock-runtime',
        region_name=bedrock_region,
        config=Config(
            retries = {
                'max_attempts': 30
            }
        )
    )
    parameters = {
        "max_tokens":maxOutputTokens,     
        "temperature":0.1,
        "top_k":250,
        "top_p":0.9,
        "stop_sequences": [STOP_SEQUENCE]
    }
    # print('parameters: ', parameters)

    chat = ChatBedrock(   # new chat model
        model_id=modelId,
        client=boto3_bedrock, 
        model_kwargs=parameters,
        region_name=bedrock_region
    )    
    if multi_region=='Enable':
        selected_chat = selected_chat + 1
        if selected_chat == number_of_models:
            selected_chat = 0
    else:
        selected_chat = 0

    return chat

def traslation(chat, text, input_language, output_language):
    system = (
        "You are a helpful assistant that translates {input_language} to {output_language} in <article> tags." 
        "Put it in <result> tags."
    )
    human = "<article>{text}</article>"
    
    prompt = ChatPromptTemplate.from_messages([("system", system), ("human", human)])
    # print('prompt: ', prompt)
    
    chain = prompt | chat    
    try: 
        result = chain.invoke(
            {
                "input_language": input_language,
                "output_language": output_language,
                "text": text,
            }
        )
        
        msg = result.content
        # print('translated text: ', msg)
    except Exception:
        err_msg = traceback.format_exc()
        print('error message: ', err_msg)                    
        raise Exception ("Not able to request to LLM")

    return msg[msg.find('<result>')+8:len(msg)-9] # remove <result> tag

def get_current_time(format: str=f"%Y-%m-%d %H:%M:%S")->str:
    """Returns the current date and time in the specified format"""
    # f"%Y-%m-%d %H:%M:%S"
    
    format = format.replace('\'','')
    timestr = datetime.datetime.now(timezone('Asia/Seoul')).strftime(format)
    print('timestr:', timestr)
    
    return timestr

def get_weather_info(city: str) -> str:
    """
    retrieve weather information by city name and then return weather statement.
    city: the name of city to retrieve
    return: weather statement
    """    
    
    city = city.replace('\n','')
    city = city.replace('\'','')
    city = city.replace('\"','')
                
    chat = get_chat()
    if isKorean(city):
        place = traslation(chat, city, "Korean", "English")
        print('city (translated): ', place)
    else:
        place = city
        city = traslation(chat, city, "English", "Korean")
        print('city (translated): ', city)
        
    print('place: ', place)
    
    weather_str: str = f"{city}에 대한 날씨 정보가 없습니다."
    if weather_api_key: 
        apiKey = weather_api_key
        lang = 'en' 
        units = 'metric' 
        api = f"https://api.openweathermap.org/data/2.5/weather?q={place}&APPID={apiKey}&lang={lang}&units={units}"
        # print('api: ', api)
                
        try:
            result = requests.get(api)
            result = json.loads(result.text)
            print('result: ', result)
        
            if 'weather' in result:
                overall = result['weather'][0]['main']
                current_temp = result['main']['temp']
                min_temp = result['main']['temp_min']
                max_temp = result['main']['temp_max']
                humidity = result['main']['humidity']
                wind_speed = result['wind']['speed']
                cloud = result['clouds']['all']
                
                weather_str = f"{city}의 현재 날씨의 특징은 {overall}이며, 현재 온도는 {current_temp} 입니다. 현재 습도는 {humidity}% 이고, 바람은 초당 {wind_speed} 미터 입니다. 구름은 {cloud}% 입니다."                
                #weather_str = f"{city}의 현재 날씨의 특징은 {overall}이며, 현재 온도는 {current_temp}도 이고, 최저온도는 {min_temp}도, 최고 온도는 {max_temp}도 입니다. 현재 습도는 {humidity}% 이고, 바람은 초당 {wind_speed} 미터 입니다. 구름은 {cloud}% 입니다."
                #weather_str = f"Today, the overall of {city} is {overall}, current temperature is {current_temp} degree, min temperature is {min_temp} degree, highest temperature is {max_temp} degree. huminity is {humidity}%, wind status is {wind_speed} meter per second. the amount of cloud is {cloud}%."            
        except Exception:
            err_msg = traceback.format_exc()
            print('error message: ', err_msg)                    
            # raise Exception ("Not able to request to LLM")    
        
    print('weather_str: ', weather_str)                            
    return weather_str

def search_by_tavily(keyword: str) -> str:
    """
    Search general information by keyword and then return the result as a string.
    keyword: search keyword
    return: the information of keyword
    """    
    answer = ""
    
    if tavily_key:
        keyword = keyword.replace('\'','')
        
        search = TavilySearchResults(
            max_results=2,
            include_answer=True,
            include_raw_content=True,
            api_wrapper=tavily_api_wrapper,
            search_depth="advanced", # "basic"
            # include_domains=["google.com", "naver.com"]
        )
                    
        try: 
            output = search.invoke(keyword)
            print('tavily output: ', output)
            
            for result in output:
                print('result: ', result)
                if result:
                    content = result.get("content")
                    url = result.get("url")                    
                    answer = answer + f"{content}, URL: {url}\n\n"
        
        except Exception:
            err_msg = traceback.format_exc()
            print('error message: ', err_msg)                    
            # raise Exception ("Not able to request to tavily")   
    
    if answer == "":
        # answer = "No relevant documents found." 
        answer = "관련된 정보를 찾지 못하였습니다."

    return answer

def stock_data_lookup(ticker, country):
    """
    Retrieve accurate stock trends for a given ticker.
    ticker: the ticker to retrieve price history for
    country: the english country name of the stock
    return: the information of ticker
    """ 
    com = re.compile('[a-zA-Z]') 
    alphabet = com.findall(ticker)
    print('alphabet: ', alphabet)

    print("country:", country)

    if len(alphabet)==0:        
        if country == "South Korea" or country == "Korea":
            ticker += ".KS"
        elif country == "Japan":
            ticker += ".T"
    print("ticker:", ticker)

    result = ""
    for attempt in range(5):    
        try: 
            stock = yf.Ticker(ticker)
            
            # get the price history for past 1 month
            history = stock.history(period="1mo")
            print('history: ', history)
            
            result = f"## Trading History\n{history}"
            #history.reset_index().to_json(orient="split", index=False, date_format="iso")    
            
            result += f"\n\n## Financials\n{stock.financials}"    
            print('financials: ', stock.financials)

            result += f"\n\n## Major Holders\n{stock.major_holders}"
            print('major_holders: ', stock.major_holders)

            print('result: ', result)
            break

        except Exception:
                err_msg = traceback.format_exc()
                print('error message: ', err_msg)    
        
    if result == "":
        result = "Not available to use the yahoo finance api"    

    return result

numberOfDocs = 3
knowledge_base_name = projectName
s3_prefix = 'docs'
doc_prefix = s3_prefix+'/'

knowledge_base_id = ""
                
class GradeDocuments(BaseModel):
    """Binary score for relevance check on retrieved documents."""

    binary_score: str = Field(description="Documents are relevant to the question, 'yes' or 'no'")

def get_retrieval_grader(chat):
    system = (
        "You are a grader assessing relevance of a retrieved document to a user question."
        "If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant."
        "Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question."
    )

    grade_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system),
            ("human", "Retrieved document: \n\n {document} \n\n User question: {question}"),
        ]
    )    
    structured_llm_grader = chat.with_structured_output(GradeDocuments)
    retrieval_grader = grade_prompt | structured_llm_grader
    return retrieval_grader

def grade_documents(question, documents):
    print("###### grade_documents ######")
    
    print("start grading...")    
    # Score each doc    
    filtered_docs = []
    chat = get_chat()

    for attempt in range(5):
        print(f"attempt: {attempt}")
        try:
            retrieval_grader = get_retrieval_grader(chat)
            for i, doc in enumerate(documents):
                # print('doc: ', doc)
                
                score = retrieval_grader.invoke({"question": question, "document": doc.page_content})
                # print("score: ", score)
                
                grade = score.binary_score
                # print(f"--> grade: {grade}")
                # Document relevant
                if grade.lower() == "yes":
                    print("---GRADE: DOCUMENT RELEVANT---")
                    filtered_docs.append(doc)
                # Document not relevant
                else:
                    print("---GRADE: DOCUMENT NOT RELEVANT---")
                    # We do not include the document in filtered_docs
                    # We set a flag to indicate that we want to run web search
                    continue            
            break
        except Exception:
            err_msg = traceback.format_exc()
            print('error message: ', err_msg)    

    return filtered_docs

contentList = []
def check_duplication(docs):
    global contentList
    length_original = len(docs)
    
    updated_docs = []
    print('length of relevant_docs:', len(docs))
    for doc in docs:            
        if doc.page_content in contentList:
            print('duplicated!')
            continue
        contentList.append(doc.page_content)
        updated_docs.append(doc)            
    length_updated_docs = len(updated_docs)   
    
    if length_original == length_updated_docs:
        print('no duplication')
    else:
        print('length of updated relevant_docs: ', length_updated_docs)
    
    return updated_docs

def search_by_knowledge_base(keyword: str) -> str:
    """
    Search technical information by keyword and then return the result as a string.
    keyword: search keyword
    return: the technical information of keyword
    """    
    print("###### search_by_knowledge_base ######")    
    
    global contentList, knowledge_base_id
    contentList = []
 
    print('keyword: ', keyword)
    keyword = keyword.replace('\'','')
    keyword = keyword.replace('|','')
    keyword = keyword.replace('\n','')
    print('modified keyword: ', keyword)
    
    top_k = numberOfDocs
    relevant_docs = []
    filtered_docs = []
    relevant_context = ""

    if knowledge_base_id:    
        try:
            retriever = AmazonKnowledgeBasesRetriever(
                knowledge_base_id=knowledge_base_id, 
                retrieval_config={"vectorSearchConfiguration": {
                    "numberOfResults": top_k,
                    "overrideSearchType": "HYBRID"   # SEMANTIC
                }},
            )
            
            docs = retriever.invoke(keyword)
            print('length of docs: ', len(docs))        
            # print('docs: ', docs)

            print('--> docs from knowledge base')
            for i, doc in enumerate(docs):
                # print_doc(i, doc)
                
                content = f"{keyword}에 대해 조사한 결과는 아래와 같습니다.\n\n"
                if doc.page_content:
                    content = doc.page_content
                
                score = doc.metadata["score"]
                
                link = ""
                if "s3Location" in doc.metadata["location"]:
                    link = doc.metadata["location"]["s3Location"]["uri"] if doc.metadata["location"]["s3Location"]["uri"] is not None else ""
                    
                    # print('link:', link)    
                    pos = link.find(f"/{doc_prefix}")
                    name = link[pos+len(doc_prefix)+1:]
                    encoded_name = parse.quote(name)
                    # print('name:', name)
                    link = f"{path}/{doc_prefix}{encoded_name}"
                    
                elif "webLocation" in doc.metadata["location"]:
                    link = doc.metadata["location"]["webLocation"]["url"] if doc.metadata["location"]["webLocation"]["url"] is not None else ""
                    name = "WEB"

                url = link
                # print('url:', url)
                
                relevant_docs.append(
                    Document(
                        page_content=content,
                        metadata={
                            'name': name,
                            'score': score,
                            'url': url,
                            'from': 'RAG'
                        },
                    )
                )    

            # no grading    
            if len(relevant_docs):
                relevant_context = ""
                for i, document in enumerate(relevant_docs):
                    print(f"{i}: {document}")
                    relevant_context += document.page_content + "\n\n"        
                print('relevant_context: ', relevant_context)     
        except Exception:
            err_msg = traceback.format_exc()
            print('error message: ', err_msg)    

    # grading                
    # if len(relevant_docs):
    #     filtered_docs = grade_documents(keyword, relevant_docs)
    #     filtered_docs = check_duplication(filtered_docs) # duplication checker
        
    # relevant_context = ""
    # if len(filtered_docs):
    #     for i, document in enumerate(filtered_docs):
    #         print(f"{i}: {document}")
    #         relevant_context += document.page_content + "\n\n"        
    #     print('relevant_context: ', relevant_context)        

    if not relevant_context:
        relevant_context = "관련된 정보를 찾지 못하였습니다."
    
    return relevant_context
    
def lambda_handler(event, context):
    print('event: ', event)
    
    agent = event['agent']
    print('agent: ', agent)    
    actionGroup = event['actionGroup']
    print('actionGroup: ', actionGroup)    
    function = event['function']
    print('function: ', function)
    parameters = event.get('parameters', [])
    print('parameters: ', parameters)

    # retrieve knowledge_base_id
    global knowledge_base_id
    if not knowledge_base_id:
        try: 
            client = boto3.client(
                service_name='bedrock-agent',
                region_name=bedrock_region
            )   
            response = client.list_knowledge_bases(
                maxResults=5
            )
            print('(list_knowledge_bases) response: ', response)
            
            if "knowledgeBaseSummaries" in response:
                summaries = response["knowledgeBaseSummaries"]
                for summary in summaries:
                    if summary["name"] == knowledge_base_name:
                        knowledge_base_id = summary["knowledgeBaseId"]
                        print('knowledge_base_id: ', knowledge_base_id)
        except Exception:
            err_msg = traceback.format_exc()
            print('error message: ', err_msg)    
    
    if function == 'current_time':
        name = parameters[0]['name']
        print('name: ', name)
        format = parameters[0]['value']
        print('format: ', format)
        output = get_current_time(format)        

    elif function == 'book_list':
        name = parameters[0]['name']
        print('name: ', name)
        keyword = parameters[0]['value']
        print('keyword: ', keyword)
        output = get_book_list(keyword)     

    elif function == 'weather':
        name = parameters[0]['name']
        print('name: ', name)
        city = parameters[0]['value']
        print('city: ', city)      
        output = get_weather_info(city)

    elif function == 'search_internet':
        name = parameters[0]['name']
        print('name: ', name)
        keyword = parameters[0]['value']
        print('keyword: ', keyword)
        output = search_by_tavily(keyword)
        
    elif function == 'search_rag':
        name = parameters[0]['name']
        print('name: ', name)
        keyword = parameters[0]['value']
        print('keyword: ', keyword)
        output = search_by_knowledge_base(keyword)

    elif function == 'stock':
        country = ticker = ""
        for p in parameters:
            if p['name'] == 'country':
                country = p['value']
                print('country: ', country)
            if p['name'] == 'ticker':
                ticker = p['value']
                print('ticker: ', ticker)

        output = stock_data_lookup(ticker, country)
        
    responseBody =  {
        "TEXT": {
            "body": output
        }
    }

    action_response = {
        'actionGroup': actionGroup,
        'function': function,
        'functionResponse': {
            'responseBody': responseBody
        }
    }

    response = {
        'response': action_response, 
        'messageVersion': event['messageVersion']
    }
    print(f"response: {response}")
    
    return response
